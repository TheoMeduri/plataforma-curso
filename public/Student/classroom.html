<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/remixicon/4.5.0/remixicon.css">
    <link rel="stylesheet" href="../assets/css/style.css">
    <style>
        body {
            position: relative;
            height: 100vh;
        }
    </style>
</head>
<body>
    <div class="infos-class">
        <h1>Aula #103</h1>
        <p>Aprendendo a programar python.</p>
    </div>

    <div class="peoples">
        <div class="person">
            <span id="user-img">TM</span>
            <h3 id="user-name">Theo Meduri</h3>
            <div class="infos-person">
                <span id="micro"><i class="ri-mic-line"></i></span>
                <span id="camera"><i class="ri-camera-line"></i></span>
            </div>
        </div>
    </div>

    <div class="call-btns">
        <div class="principais">
            <button id="mic"><i class="ri-mic-line"></i></button>
            <button id="cam"><i class="ri-camera-line"></i></button>
            <button id="apresent"><i class="ri-device-line"></i></button>
            <button id="exit"><i class="ri-phone-line"></i></button>
        </div>
        
        <div class="second">
            <button id="task"><i class="ri-clipboard-line"></i></button>
            <button id="chat"><i class="ri-message-3-line"></i></button>
        </div>
    </div>

    <script>
        // Seleciona os botões pela ID
        const micButton = document.getElementById('mic');
        const micInfos = document.getElementById('micro');
        const camButton = document.getElementById('cam');
        const camInfos = document.getElementById('camera');
        const apresentButton = document.getElementById('apresent');
        const exitButton = document.getElementById('exit');

        // Carrega os arquivos de som
        const muteSound = new Audio('../audio/mute.mp3');
        const unmuteSound = new Audio('../audio/unmute.mp3');


        let micStream;  // Variável para armazenar o fluxo do microfone

        // Captura o áudio do microfone
        async function startMic() {
            try {
                micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const micTrack = micStream.getAudioTracks()[0]; // A primeira faixa de áudio
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const analyser = audioContext.createAnalyser();
                const source = audioContext.createMediaStreamSource(micStream);
                source.connect(analyser);

                // Configura o analisador para capturar os dados de volume
                analyser.fftSize = 256;
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);

                function detectSound() {
                    analyser.getByteFrequencyData(dataArray);
                    let sum = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        sum += dataArray[i];  // Soma os valores de frequência
                    }
                    let average = sum / bufferLength;  // Calcula a média do volume

                    if (average > 20) {  // Valor de referência para detectar quando está falando
                        // Se estiver falando, adiciona a borda de destaque
                        document.getElementById('user-img').style.border = '4px solid var(--success-color)';
                        document.getElementById('user-img').style.boxShadow = '0 0 8px var(--success-color)';
                    } else {
                        // Se não estiver falando, remove a borda de destaque
                        document.getElementById('user-img').style.border = '';
                        document.getElementById('user-img').style.boxShadow = '';
                    }

                    requestAnimationFrame(detectSound);  // Continuar verificando o áudio
                }

                detectSound();  // Começa a detecção de som
            } catch (error) {
                console.error('Erro ao capturar o microfone:', error);
            }
        }

        micButton.addEventListener('click', () => {
            let isMicOn = micButton.classList.toggle('active');
            if (isMicOn) {
                micButton.innerHTML = '<i class="ri-mic-off-line"></i>';
                micInfos.innerHTML = '<i class="ri-mic-off-line"></i>';
                muteSound.play();  // Toca o som de mute

                // Desativa o áudio
                if (micStream) {
                    micStream.getTracks().forEach(track => track.stop()); // Para o microfone
                }
                
                // Para o som de mute após 500ms
                setTimeout(function() {
                    muteSound.pause();
                    muteSound.currentTime = 0;
                }, 500);
            } else {
                micButton.innerHTML = '<i class="ri-mic-line"></i>';
                micInfos.innerHTML = '<i class="ri-mic-line"></i>';
                unmuteSound.play();  // Toca o som de unmute

                // Ativa o áudio novamente
                startMic(); // Inicia a captura do microfone e detecção de som

                // Para o som de unmute após 500ms
                setTimeout(function() {
                    unmuteSound.pause();
                    unmuteSound.currentTime = 0;
                }, 500);
            }
        });


        // Função para alternar a câmera
        camButton.addEventListener('click', () => {
            let isCamOn = camButton.classList.toggle('active');
            if (isCamOn) {
                camButton.innerHTML = '<i class="ri-camera-off-line"></i>';
                camInfos.innerHTML = '<i class="ri-camera-off-line"></i>';
            } else {
                camButton.innerHTML = '<i class="ri-camera-line"></i>';
                camInfos.innerHTML = '<i class="ri-camera-line"></i>';
            }
                });
                
                const peoplesContainer = document.querySelector('.peoples'); // Seleciona a div .peoples para inserir o vídeo

// Variável para armazenar a transmissão de mídia
let screenStream;

// Função para iniciar/parar a apresentação
apresentButton.addEventListener('click', async () => {
    let isPresenting = apresentButton.classList.toggle('active2');
    if (isPresenting) {
        try {
            screenStream = await navigator.mediaDevices.getDisplayMedia({
                video: {
                    width: { ideal: 1920 },  // Resolução desejada
                    height: { ideal: 1080 },
                    frameRate: { ideal: 200 },  // Taxa de quadros desejada
                },
                audio: false
            });


            // Exibe o ícone de parar apresentação
            apresentButton.innerHTML = '<i class="ri-close-large-line"></i>';

            // Cria uma div .person e o elemento de vídeo para mostrar a tela compartilhada
            const personDiv = document.createElement('div');
            personDiv.classList.add('person', 'apresent'); // Adiciona as classes .person e .apresent

            const videoElement = document.createElement('video');
            videoElement.classList.add('screen-video'); // Classe opcional para estilizar o vídeo
            videoElement.srcObject = screenStream;
            videoElement.autoplay = true;
            videoElement.muted = true; // Opcional, para que o próprio usuário não ouça eco

            // Insere o vídeo dentro da div .person e a div .person dentro de .peoples
            personDiv.appendChild(videoElement);
            peoplesContainer.appendChild(personDiv);

            // Adiciona o evento para tela cheia no vídeo ao clicar
            videoElement.addEventListener('click', () => {
                if (videoElement.requestFullscreen) {
                    videoElement.requestFullscreen(); // Padrão
                } else if (videoElement.webkitRequestFullscreen) { // Safari
                    videoElement.webkitRequestFullscreen();
                } else if (videoElement.msRequestFullscreen) { // IE/Edge
                    videoElement.msRequestFullscreen();
                }
            });

            // Ouvinte para detectar o fim do compartilhamento de tela
            screenStream.getVideoTracks()[0].addEventListener('ended', () => {
                // Desativa o modo de apresentação quando o usuário para manualmente
                apresentButton.classList.remove('active2');
                apresentButton.innerHTML = '<i class="ri-device-line"></i>';
                
                // Remove a div .person quando o compartilhamento for encerrado
                personDiv.remove();
            });

        } catch (error) {
            console.error("Erro ao iniciar o compartilhamento de tela:", error);
            apresentButton.classList.remove('active2');
        }
    } else {
        // Encerra o compartilhamento de tela
        if (screenStream) {
            screenStream.getTracks().forEach(track => track.stop()); // Para todos os fluxos de vídeo
            screenStream = null;
        }
        apresentButton.innerHTML = '<i class="ri-device-line"></i>';
        
        // Remove a div .person se o botão de apresentação for desativado
        const personDiv = document.querySelector('.person.apresent');
        if (personDiv) personDiv.remove();
    }
});

        // Função para encerrar a chamada
        exitButton.addEventListener('click', () => {
            console.log("Saindo da chamada");
            alert("Você saiu da chamada");
            // Aqui você pode adicionar a lógica para encerrar a chamada, como redirecionar para outra página
        });

    </script>
</body>
</html>